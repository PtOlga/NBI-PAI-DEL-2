{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4371e9fd-6e89-44c2-997e-c89cbd615bf4",
   "metadata": {},
   "source": [
    "# För att modellera MNIST-data kommer jag att använda två olika modeller: Random Forest Classifier och SVM. \n",
    "# Jag kommer att utvärdera båda modellerna och välja den bäst presterande modellen för slutlig utvärdering på testdata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1712211-3cdf-4383-8fad-071272fddcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '554', 'name': 'mnist_784', 'version': '1', 'description_version': '2', 'format': 'ARFF', 'creator': ['Yann LeCun', 'Corinna Cortes', 'Christopher J.C. Burges'], 'upload_date': '2014-09-29T03:28:38', 'language': 'English', 'licence': 'Public', 'url': 'https://api.openml.org/data/v1/download/52667/mnist_784.arff', 'parquet_url': 'https://openml1.win.tue.nl/datasets/0000/0554/dataset_554.pq', 'file_id': '52667', 'default_target_attribute': 'class', 'tag': ['Artificial Intelligence', 'AzurePilot', 'Computer Vision', 'Data Sets', 'Kaggle', 'Machine Learning', 'OpenML-CC18', 'OpenML100', 'study_1', 'study_123', 'study_41', 'study_99', 'vision'], 'visibility': 'public', 'minio_url': 'https://openml1.win.tue.nl/datasets/0000/0554/dataset_554.pq', 'status': 'active', 'processing_date': '2020-11-20 20:12:09', 'md5_checksum': '0298d579eb1b86163de7723944c7e495'}\n"
     ]
    }
   ],
   "source": [
    "## Steg 1: Ladda in data\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Ladda MNIST-datan\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "# print(mnist.descr)\n",
    "print(mnist.details)  # Använd rätt attribut :)\n",
    "\n",
    "X = mnist['data']\n",
    "y = mnist['target'].astype(np.uint8)\n",
    "\n",
    "# Mata ut de första 5 raderna med data som en DataFrame\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(X)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fc84cdb-ea4e-4a46-97dd-c83d607a17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dela upp datan i tränings- och testset\n",
    "# X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "# därför att Jag har inte tillräckligt med ledigt minne på min bärbara dator, \n",
    "# då kommer jag att minska urvalet och samtidigt jämföra resultaten av modellerna på prover av olika datastorlekar\n",
    "X_train, X_test, y_train, y_test = X[:10000], X[10000:], y[:10000], y[10000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a16de9bc-bc28-4620-b260-d481c05c49cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      5902\n",
      "           1       0.97      0.98      0.98      6750\n",
      "           2       0.93      0.94      0.94      5999\n",
      "           3       0.94      0.93      0.93      6109\n",
      "           4       0.95      0.95      0.95      5844\n",
      "           5       0.95      0.93      0.94      5450\n",
      "           6       0.96      0.97      0.97      5862\n",
      "           7       0.95      0.95      0.95      6223\n",
      "           8       0.94      0.92      0.93      5881\n",
      "           9       0.92      0.92      0.92      5980\n",
      "\n",
      "    accuracy                           0.95     60000\n",
      "   macro avg       0.95      0.95      0.95     60000\n",
      "weighted avg       0.95      0.95      0.95     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Steg 2: Träna och utvärdera modeller\n",
    "\n",
    "# Modell 1: Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Skapa och träna modellen\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Gör prediktioner på testdata\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac7aa52a-89c3-4ec4-abbb-94ca9fcd0dab",
   "metadata": {},
   "source": [
    "## 4. Modellsammanfattning 1 Random Forest Classifier\n",
    "\n",
    "## på ett urval av 60 000 var resultaten som följer (data sparas till fil 60000.jpg)\n",
    "# - Modellen visar hög klassificeringskvalitet för alla klasser, eftersom värdena för 'precision', 'recall' och 'f1-score' är nära 1.\n",
    "# - Modellen fungerar bäst för klass \"1\", där alla mätvärden är lika med 0,99.\n",
    "# - Modellen predikterar sämst (men fortfarande bra) för klasserna \"8\" och \"9\", där \"f1-score\" är 0,96.\n",
    "# - modellens totala noggrannhet är 97 %, vilket är ett mycket bra resultat för MNIST-klassificeringsuppgiften.\n",
    "\n",
    "## på ett urval av 10000 är resultaten som följer\n",
    "# - Modellens klassificeringskvalitet har minskat till 0,95, men är fortfarande ganska hög\n",
    "# - Den bästa klassen förblir 1 med värdet 0,97\n",
    "# - Modellen predikterar sämst för klasserna \"2\" och \"9\"\n",
    "# - Modellens totala noggrannhet är 95 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10a70d79-9754-42d4-83b7-862c4413bf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      5902\n",
      "           1       0.94      0.98      0.96      6750\n",
      "           2       0.88      0.90      0.89      5999\n",
      "           3       0.87      0.88      0.88      6109\n",
      "           4       0.89      0.93      0.91      5844\n",
      "           5       0.89      0.85      0.87      5450\n",
      "           6       0.94      0.95      0.94      5862\n",
      "           7       0.92      0.92      0.92      6223\n",
      "           8       0.90      0.84      0.87      5881\n",
      "           9       0.89      0.83      0.86      5980\n",
      "\n",
      "    accuracy                           0.91     60000\n",
      "   macro avg       0.91      0.91      0.91     60000\n",
      "weighted avg       0.91      0.91      0.91     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modell 2: Support Vector Machine \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Skapa och träna modellen\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Gör prediktioner på testdata\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11f691bc-d2ad-4cf5-9474-4e8aedb08241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9467166666666667\n",
      "SVM Accuracy: 0.9072666666666667\n"
     ]
    }
   ],
   "source": [
    "## Steg 3: Jämföra modeller och välja den bästa\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ba5bc-92ab-4690-bfa1-bcb6f2bc3919",
   "metadata": {},
   "source": [
    "## Steg 3: \n",
    "# Slutsats: SVM-modellen är sämre vad gäller parametrar och prestanda (användning av datorresurser) än ett Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5a475e2-b96f-4fc8-b12d-f55404a4c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Steg 4: Spara den bästa modellen med `joblib` \n",
    "\n",
    "import joblib\n",
    "\n",
    "# Spara den bästa modellen\n",
    "joblib.dump(rf_clf, 'best_model.joblib')\n",
    "\n",
    "# Ladda modellen senare\n",
    "loaded_model = joblib.load('best_model.joblib')\n",
    "\n",
    "# Använd den laddade modellen för prediktioner\n",
    "predictions = loaded_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894b9b3-6cbd-4c9e-9aca-ebebfe89a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sammanfattning\n",
    "# - Jag har laddat in MNIST-datan och förberett den för modellering.\n",
    "# - Jag har tränat och utvärderat två olika modeller: Random Forest och SVM.\n",
    "# - Jag har jämfört modellernas prestanda och valt den bästa modellen.\n",
    "# - Slutligen har Jag sparat den bästa modellen för framtida användning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c8176-25a0-4908-a6e0-21b3b62a7498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
